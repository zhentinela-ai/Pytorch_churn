{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split, TensorDataset\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Set de datos\n",
    "Antes de armar la red neuronal vamos a importar los datos que se van a requerir usando pandas. Vamos a hacer un preprocesamiento para que el formato sea compatible con la red neuronal que armaremos"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "datos = pd.read_csv(\"Churn_Modelling.csv\")\n",
    "datos.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Imprimiento los primeros 5 elementos podemos ver que nuestra variable destino es la ultima columna **Exited** donde 1 es que se dio de baja y 0 que se quedó.\n",
    "\n",
    "Es importante que en este paso vayamos pensando que tendremos que hacer con algunas columnas, ya sea eliminarlas, normalizarlas, llevar alguna transformación etc. Por ejemplo:\n",
    "* RowNumber, CustomerID, Surname no nos dicen nada de utilidad. Predecir si alguien va a darse de baja por su ID de cliente, apellido o numero de renglon en la base de datos no nos va a dar buenos resultados. \n",
    "* Las columnas que son categoricas las vamos a transformar con **one hot encoding** (Genero y ubicacion geográfica)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Separamos la ultima columna para que sea variable destino\n",
    "datos_y = datos[datos.columns[-1]]\n",
    "datos_y.head()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Eliminamos las columnas que no funcionarán\n",
    "datos_x = datos.drop(columns=[\"RowNumber\", \"CustomerId\", \"Surname\", \"Exited\"])\n",
    "datos_x.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Convertimos en one hot encoding las columnas de genero y zona geográfica\n",
    "datos_x = pd.get_dummies(datos_x)\n",
    "datos_x.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ya se cuenta con una variable que tiene todas las entradas al modelo **datos_x** y otra con la salida **datos_y**. Para datos_x se cuenta con una columna por cada categoria de las variables Genero y Zona geofráfica.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Escalado datos\n",
    "Ahora vamos a escalar los valores para que esten dentro de un rango mas corto."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "escalador = StandardScaler()\n",
    "datos_x = escalador.fit_transform(datos_x)\n",
    "print(datos_x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dividir datos entre entrenamiento y test"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "datos_x.shape[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(datos_x, datos_y, test_size = 0.2, random_state = 2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"X Train: {}, X Test: {}, y_train: {}, y_test: {}\".format(X_train.shape, X_test.shape, y_train.shape, y_test.shape))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n_entradas = X_train.shape[1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tensores\n",
    "Para poder procesar los datos en la red neuronal necesitamos que todos los datos estén en tensores, asi que haremos las conversiones necesarias"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "t_X_train = torch.from_numpy(X_train).float().to(\"cpu\") #MPS\n",
    "t_X_test = torch.from_numpy(X_test).float().to(\"cpu\")\n",
    "t_y_train = torch.from_numpy(y_train.values).float().to(\"cpu\")\n",
    "t_y_test = torch.from_numpy(y_test.values).float().to(\"cpu\")\n",
    "t_y_train = t_y_train[:,None]\n",
    "t_y_test = t_y_test[:, None]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test = TensorDataset(t_X_test, t_y_test)\n",
    "print(test[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "t_y_train"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Estructura de la red neuronal\n",
    "Ahora vamos a armar una estructura básica de una red neuronal la cual va a recibir los datos de **X** para eventualmente poder predecir **y**\n",
    "\n",
    "Para hacer esto tenemos que crear una Clase la cual hereda de nn.Module de torch."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class Red(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_entradas):\n",
    "        super(Red, self).__init__()\n",
    "        self.linear1 = nn.Linear(n_entradas, 15)\n",
    "        self.linear2 = nn.Linear(15, 8)\n",
    "        # self.linear3 = nn.Linear(8,160)\n",
    "        # self.linear4 = nn.Linear(160, 200)\n",
    "        # self.linear5 = nn.Linear(200, 1)\n",
    "        self.linear3 = nn.Linear(8, 1)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        pred_1 = torch.sigmoid(input=self.linear1(inputs))\n",
    "        pred_2 = torch.sigmoid(input=self.linear2(pred_1))\n",
    "        # prediction = torch.sigmoid(input=self.linear3(prediction))\n",
    "        # prediction = torch.sigmoid(input=self.linear4(prediction))\n",
    "        # prediction = torch.sigmoid(input=self.linear5(prediction))\n",
    "        pred_f = torch.sigmoid(input=self.linear3(pred_2))\n",
    "        return pred_f\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "t_y_test[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%%time\n",
    "lr = 0.001\n",
    "epochs = 2000\n",
    "estatus_print = 100\n",
    "\n",
    "model = Red(n_entradas=n_entradas)\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=lr)\n",
    "print(\"Arquitectura del modelo: {}\".format(model))\n",
    "historico = pd.DataFrame()\n",
    "\n",
    "print(\"Entranando el modelo\")\n",
    "for epoch in range(1, epochs+1):\n",
    "    y_pred= model(t_X_train)\n",
    "    loss = loss_fn(input=y_pred, target=t_y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if epoch % estatus_print == 0:\n",
    "        print(f\"\\nEpoch {epoch} \\t Loss: {round(loss.item(), 4)}\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        y_pred = model(t_X_test)\n",
    "        y_pred_class = y_pred.round()\n",
    "        correct = (y_pred_class == t_y_test).sum()\n",
    "        accuracy = 100 * correct / float(len(t_y_test))\n",
    "        if epoch % estatus_print == 0:\n",
    "            print(\"Accuracy: {}\".format(accuracy.item()))\n",
    "    \n",
    "    df_tmp = pd.DataFrame(data={\n",
    "        'Epoch': epoch,\n",
    "        'Loss': round(loss.item(), 4),\n",
    "        'Accuracy': round(accuracy.item(), 4)\n",
    "    }, index=[0])\n",
    "    historico = pd.concat(objs=[historico, df_tmp], ignore_index=True, sort=False)\n",
    "\n",
    "print(\"Accuracy final: {}\".format(round(accuracy.item(), 4)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(historico['Epoch'], historico['Loss'], label='Loss')\n",
    "plt.title(\"Loss\", fontsize=25)\n",
    "plt.xlabel(\"Epoch\", fontsize=12)\n",
    "plt.ylabel(\"Loss\", fontsize=12)\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(historico['Epoch'], historico['Accuracy'], label='Accuracy')\n",
    "plt.title(\"Accuracy\", fontsize=25)\n",
    "plt.xlabel(\"Epoch\", fontsize=12)\n",
    "plt.ylabel(\"Accuracy\", fontsize=12)\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "t_X_test[5]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "prediccion = model(t_X_test[5])\n",
    "print(prediccion)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "t_y_test[5]"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('pytorch': conda)"
  },
  "interpreter": {
   "hash": "97b669972ed46336d3ec5c9253905be09aadac6dbd287963ff3ed96ab29d7383"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}